{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:25.518921Z",
     "start_time": "2020-09-25T23:09:24.833765Z"
    }
   },
   "source": [
    "# NaLIR: Python Implementation Notebook -  Tutorial SBDD 2020\n",
    "\n",
    "### Autores: Altigran da Silva, Brandell Ferreira, Lucas Citolin e Paulo Martins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse Notebook mostraremos a implementação de uma Interface de Linguage Natural para Banco de Dados. Será apresentada a arquitetura geral do Sistema, e para cada módulo, será listado o que recebem como entrada, e o que geram como saída. Além disso, mostraremos detalhes de implementação que são interessantes em cada módulo. Ao final, mostraremos alguns exemplos de consultas para as quais o NaLIR consegue obter uma SQL válida. É importante ressaltar que apenas portamos o código para Python, o código original em Java se encontra neste [repositório](https://github.com/umich-dbgroup/NaLIR)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='arquitetura_geral'></a>\n",
    "## Arquitetura Geral\n",
    "\n",
    "O NaLIR é uma Interface de Lingaugem Natural que utiliza uma estrutura derivada do Parser de Dependência para traduzir as consultas de linguagem natural para uma linguagem estruturada de consulta de banco de dados (SQL). Além de utilizar o Parser de Dependência, o NaLIR também utiliza interações com o usuário para corrigir possíveis erros na estrutura da árvore de Dependência e nos mapeamentos padrões escolhidos das palavras da consulta para elementos de Banco de Dados.\n",
    "\n",
    "Como podemos ver na figura Abaixo, A arquitetura do NaLIRpossui **5** Componentes: **Dependecy Parser**, **Query Node Mapper**, **Query Tree Strucutre Adjustor**, **Query Translator** e **Interative Comunicator**. O **Depency Parser** recebe  a consulta do usuário,e repassa a entrada para o parser de Dependêcia de Stanford. Após retirar gerar a Árvore de Depência, o **Query Node Mapper** é reponsável por mapear os nós da árvore de dependência para elementos da estrutura de uma SQL.\n",
    "\n",
    "Após a escolha dos mapementos, o **Interactive Communicatior** entra em ação pela primeira vez, fornecendo para o usuário os candidatos encontrados pelo **Query Node Mapper**. Após o usuário escolher os mapeamentos para cada Nó, **Query Tree structure Adjustor** executa um algoritmo para modificar a estrutura da Árvore para que a conversão para uma consulta SQL seja facilitada. Tais modificações são feitas seguindo uma gramática. A saída dessa etapa é uma lista de árvores, ordenadas por uma pontuação que indica o quão correta está a árvore e a relação entre os elementos do banco de dados que os nós referenciam.\n",
    "\n",
    "Pela Segunda vez, o **Interactive Comunicator** entra em ação, para que o usuário escolha qual árvore será escolhida pelo usuario. Após isso, **Query Tree Structure Adjustor** insere nós na árvore selecionada pelo usuário com o intuito de retirar possíveis elipses da consulta. Pela última vez **Interactive Commnunicator** mostra ao usuário as inserções feitas. Após a ação do usuário, a árvore de consulta é repassada para o **Query Tree Translator** que efetivamente converte a árvore para uma SQL válida.\n",
    "\n",
    "Na nossa implementação, **não portamos o Interactive Communicator**, assim o único fluxo possível é aquele em que o **NaLIR utiliza todos os mapeamentos padrões** para resolver a consulta.\n",
    "\n",
    "![Arquitetura Geral](imgs/OverallDiagram.png)\n",
    "\n",
    "É importante salientar que apesar de apenas quatro módulos estarem presentes na arquitetura do NaLIR, alguns módulos auxiliares foram implementados,como o que gerencia o acesso ao Banco de Dados. Apesar deste módulo estar presente nas entrelinhas do fluxo na Arquitetura mostrada acima, foi preciso implementá-lo para que fosse possível a construção do Sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuração do Cliente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/someone/venv37/lib/python3.7/site-packages/pandas/compat/__init__.py:120: UserWarning: Could not import the lzma module. Your installed Python is incomplete. Attempting to use lzma compression will result in a RuntimeError.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "from nalir import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "O primeiro passo é **instanciar** o objeto de configuração responsável por carregar os arquivos requeridos para que a execução do Nalir possa ser feita. A configuração é feita a partir de um objeto JSON, cujo as propriedades devem ser:\n",
    "\n",
    "| Propriedade | Tipo | Descrição |\n",
    "| :-- | :-: | :-- | \n",
    "| `connection` | Object | Armazena as configurações de conexão com o Banco de dados |\n",
    "| `connection.host`|  String | Host para a conexão com o Banco de Dados |\n",
    "| `connection.password`| String | Senha para conectar com o Banco de Dados |\n",
    "| `connection.user` | String | Usuario de Banco de Dados|\n",
    "| `connection.database` | String | Nome do Banco de Dados utilizado |\n",
    "| `logginMode` | String | Nivel de Login da Aplicação|\n",
    "| `zfiles_path`| String | Diretório onde se encontra os arquivos de configuração do NaLIR|\n",
    "| `jars_path` | String | Diretório onde se encontra os jars necessários para a execução do NaLIR |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:25.524674Z",
     "start_time": "2020-09-25T23:09:25.520353Z"
    }
   },
   "outputs": [],
   "source": [
    "config_json_text = '''{\n",
    "    \"connection\":{\n",
    "        \"host\": \"localhost\",\n",
    "        \"password\":\"root\",\n",
    "        \"user\":\"root\",\n",
    "        \"database\":\"seade\"\n",
    "    },\n",
    "    \"loggingMode\": \"ERROR\",\n",
    "    \"zfiles_path\":\"zfiles\",\n",
    "    \"jars_path\":\"jars/new_jars\"\n",
    "}\n",
    "'''\n",
    "config = ConfigHandler(reset=True,config_json_text=config_json_text)\n",
    "#config = ConfigHandler(reset=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Após colocar todas as configurações necessárias e criar o objeto, é preciso criar uma instância do módulo que gerencia o acesso ao Banco de Dados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:25.849306Z",
     "start_time": "2020-09-25T23:09:25.526005Z"
    }
   },
   "outputs": [],
   "source": [
    "rdbms = RDBMS(config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para exemplificar passo a passo como os módulos do NaLIR interagem com a consulta, utilizaremos a consulta ''return me the authors who have a paper in VLDB conference before 2002 after 1995.''."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:25.855589Z",
     "start_time": "2020-09-25T23:09:25.852274Z"
    }
   },
   "outputs": [],
   "source": [
    "#query_line='devolva tudo onde o município é \"Sao Bernardo do Campo\"'\n",
    "#query_line='devolva tudo onde a idade é maior do que 30'\n",
    "#query_line='devolva tudo onde o município é Sao_Bernardo_do_Campo'\n",
    "query_line = 'retorne a idade onde o município é São Bernardo do Campo'\n",
    "\n",
    "#usar artigo e acentos e, para nomes de cidade, usar underlines e remover as aspas duplas\n",
    "query = Query(query_line,rdbms.schema_graph)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stanford Dependency Parser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na inicialização da classe `StanfordParser` executamos 3 passos para transformar a consulta em uma árvore de dependência. Cada passo é representado por uma função no código a seguir:\n",
    "\n",
    "``` python\n",
    "     def __init__(self,query,config):\n",
    "        \n",
    "        #....\n",
    "        \n",
    "        self.parse(query)\n",
    "        self.build_tree(query)\n",
    "        self.fix_conj(query)\n",
    "        \n",
    "        #....\n",
    "```\n",
    "\n",
    "A função `parse(query)` executa o Parser de Dependência na consulta recebida, enquanto as outras `build_tree` e `fix_conj` são responsáveis por adaptar a estrutura para uma estrutura `ParseTree` definida dentro do pacote. A seguir mostramos como a função `build_tree` constrói a Árvore de Dependência a partir das dependências extraídas pelo Parser de Stanford.\n",
    "\n",
    "``` python\n",
    "    def build_tree(self,query):\n",
    "        query.parse_tree = ParseTree()\n",
    "        done_list = [False] * len(query.tree_table)\n",
    "        i = 0\n",
    "\n",
    "        for tree_table_item in query.tree_table:\n",
    "            if tree_table_item[PARENT_IDX] == 0:\n",
    "                done_list[i] = True\n",
    "                query.parse_tree.build_node(tree_table_item)\n",
    "            i+=1\n",
    "\n",
    "        finished = False\n",
    "        while not finished:\n",
    "            i = 0\n",
    "            for i in range(len(query.tree_table)):\n",
    "                if not done_list[i]:\n",
    "                    if query.parse_tree.build_node(query.tree_table[i]):\n",
    "                        done_list[i] = True\n",
    "                        break\n",
    "\n",
    "\n",
    "            finished = True\n",
    "            for done_list_item in done_list:\n",
    "                if not done_list_item:\n",
    "                    finished = False\n",
    "                    break\n",
    "\n",
    "```\n",
    "\n",
    "A tabela `query.tree_table` é criada em `parse(query)`. `fix_conj()` corrige relações de conjunção (quando duas palavras estão conectadas por \"e\" ou \"ou\"). Abaixo temos o exemplo da saída do módulo. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:27.104088Z",
     "start_time": "2020-09-25T23:09:25.857005Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TEXTO DENTRO DO NALIR:  retorne a idade onde o município é igual a São Bernardo do Campo\n",
      "STANFORD PARSER CHEGOU ATÉ AQUI\n",
      "QUERY TREE:  [[1, 'retorne', 'VERB', 0, 'ROOT', 'root'], [2, 'a', 'DET', 3, 'idade', 'det'], [3, 'idade', 'NOUN', 1, 'retorne', 'obj'], [4, 'onde', 'PRON', 8, 'igual', 'obl'], [5, 'o', 'DET', 6, 'município', 'det'], [6, 'município', 'NOUN', 8, 'igual', 'nsubj'], [7, 'é', 'AUX', 8, 'igual', 'cop'], [8, 'igual', 'ADJ', 3, 'idade', 'acl:relcl'], [9, 'a', 'ADP', 10, 'São', 'case'], [10, 'São', 'PROPN', 8, 'igual', 'obl'], [11, 'Bernardo', 'PROPN', 10, 'São', 'flat:name'], [12, 'do', 'ADP', 13, 'Campo', 'case'], [13, 'Campo', 'PROPN', 10, 'São', 'nmod']]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14)ROOT\n",
       "    (15)retorne\n",
       "        (16)idade\n",
       "            (17)a\n",
       "            (18)igual\n",
       "                (19)onde\n",
       "                (20)município\n",
       "                    (21)o\n",
       "                (22)é\n",
       "                (23)São\n",
       "                    (24)a\n",
       "                    (25)Bernardo\n",
       "                    (26)Campo\n",
       "                        (27)do"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "StanfordParser(query,config)\n",
    "query.parse_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nota**: O graph vizualitation possui o programa [Graphviz](https://graphviz.org/)  como dependêcia, logo ele precisa ser instalado. Verifique no site como é possível baixá-lo para seu sistema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:27.135015Z",
     "start_time": "2020-09-25T23:09:27.105509Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"480pt\" height=\"476pt\"\n",
       " viewBox=\"0.00 0.00 480.04 476.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 472)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-472 476.04,-472 476.04,4 -4,4\"/>\n",
       "<!-- 0.14 &#45; ROOT -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0.14 &#45; ROOT</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"150.15\" cy=\"-450\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.15\" y=\"-446.3\" font-family=\"Times,serif\" font-size=\"14.00\">ROOT</text>\n",
       "</g>\n",
       "<!-- 14 &#45; ROOT.15 &#45; retorne -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>14 &#45; ROOT.15 &#45; retorne</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"150.15\" cy=\"-378\" rx=\"45.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.15\" y=\"-374.3\" font-family=\"Times,serif\" font-size=\"14.00\">retorne</text>\n",
       "</g>\n",
       "<!-- 0.14 &#45; ROOT&#45;&gt;14 &#45; ROOT.15 &#45; retorne -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0.14 &#45; ROOT&#45;&gt;14 &#45; ROOT.15 &#45; retorne</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150.15,-431.7C150.15,-423.98 150.15,-414.71 150.15,-406.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"153.65,-406.1 150.15,-396.1 146.65,-406.1 153.65,-406.1\"/>\n",
       "</g>\n",
       "<!-- 15 &#45; retorne.16 &#45; idade -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>15 &#45; retorne.16 &#45; idade</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"150.15\" cy=\"-306\" rx=\"36.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"150.15\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">idade</text>\n",
       "</g>\n",
       "<!-- 14 &#45; ROOT.15 &#45; retorne&#45;&gt;15 &#45; retorne.16 &#45; idade -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>14 &#45; ROOT.15 &#45; retorne&#45;&gt;15 &#45; retorne.16 &#45; idade</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M150.15,-359.7C150.15,-351.98 150.15,-342.71 150.15,-334.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"153.65,-334.1 150.15,-324.1 146.65,-334.1 153.65,-334.1\"/>\n",
       "</g>\n",
       "<!-- 16 &#45; idade.17 &#45; a -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>16 &#45; idade.17 &#45; a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"111.15\" cy=\"-234\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"111.15\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "<!-- 15 &#45; retorne.16 &#45; idade&#45;&gt;16 &#45; idade.17 &#45; a -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>15 &#45; retorne.16 &#45; idade&#45;&gt;16 &#45; idade.17 &#45; a</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.9,-288.41C136.24,-280.04 130.49,-269.71 125.28,-260.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"128.25,-258.5 120.32,-251.47 122.13,-261.91 128.25,-258.5\"/>\n",
       "</g>\n",
       "<!-- 16 &#45; idade.18 &#45; igual -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>16 &#45; idade.18 &#45; igual</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"190.15\" cy=\"-234\" rx=\"33.6\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"190.15\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">igual</text>\n",
       "</g>\n",
       "<!-- 15 &#45; retorne.16 &#45; idade&#45;&gt;16 &#45; idade.18 &#45; igual -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>15 &#45; retorne.16 &#45; idade&#45;&gt;16 &#45; idade.18 &#45; igual</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M159.63,-288.41C164.41,-280.04 170.31,-269.71 175.65,-260.37\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"178.81,-261.89 180.74,-251.47 172.74,-258.42 178.81,-261.89\"/>\n",
       "</g>\n",
       "<!-- 18 &#45; igual.19 &#45; onde -->\n",
       "<g id=\"node6\" class=\"node\">\n",
       "<title>18 &#45; igual.19 &#45; onde</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"33.15\" cy=\"-162\" rx=\"33.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"33.15\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">onde</text>\n",
       "</g>\n",
       "<!-- 16 &#45; idade.18 &#45; igual&#45;&gt;18 &#45; igual.19 &#45; onde -->\n",
       "<g id=\"edge5\" class=\"edge\">\n",
       "<title>16 &#45; idade.18 &#45; igual&#45;&gt;18 &#45; igual.19 &#45; onde</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M164.92,-221.75C138.52,-209.98 96.9,-191.43 67.51,-178.32\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"68.61,-174.98 58.05,-174.1 65.76,-181.37 68.61,-174.98\"/>\n",
       "</g>\n",
       "<!-- 18 &#45; igual.20 &#45; município -->\n",
       "<g id=\"node7\" class=\"node\">\n",
       "<title>18 &#45; igual.20 &#45; município</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"140.15\" cy=\"-162\" rx=\"55.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"140.15\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">município</text>\n",
       "</g>\n",
       "<!-- 16 &#45; idade.18 &#45; igual&#45;&gt;18 &#45; igual.20 &#45; município -->\n",
       "<g id=\"edge6\" class=\"edge\">\n",
       "<title>16 &#45; idade.18 &#45; igual&#45;&gt;18 &#45; igual.20 &#45; município</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M178.55,-216.76C172.45,-208.23 164.85,-197.58 158.02,-188.02\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"160.69,-185.74 152.03,-179.63 154.99,-189.81 160.69,-185.74\"/>\n",
       "</g>\n",
       "<!-- 18 &#45; igual.22 &#45; é -->\n",
       "<g id=\"node9\" class=\"node\">\n",
       "<title>18 &#45; igual.22 &#45; é</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"241.15\" cy=\"-162\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"241.15\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">é</text>\n",
       "</g>\n",
       "<!-- 16 &#45; idade.18 &#45; igual&#45;&gt;18 &#45; igual.22 &#45; é -->\n",
       "<g id=\"edge8\" class=\"edge\">\n",
       "<title>16 &#45; idade.18 &#45; igual&#45;&gt;18 &#45; igual.22 &#45; é</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M201.98,-216.76C208.44,-207.89 216.57,-196.74 223.74,-186.89\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"226.67,-188.81 229.73,-178.67 221.02,-184.69 226.67,-188.81\"/>\n",
       "</g>\n",
       "<!-- 18 &#45; igual.23 &#45; São -->\n",
       "<g id=\"node10\" class=\"node\">\n",
       "<title>18 &#45; igual.23 &#45; São</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"314.15\" cy=\"-162\" rx=\"27.9\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"314.15\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">São</text>\n",
       "</g>\n",
       "<!-- 16 &#45; idade.18 &#45; igual&#45;&gt;18 &#45; igual.23 &#45; São -->\n",
       "<g id=\"edge9\" class=\"edge\">\n",
       "<title>16 &#45; idade.18 &#45; igual&#45;&gt;18 &#45; igual.23 &#45; São</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M212.6,-220.32C232.88,-208.88 262.83,-191.97 284.96,-179.48\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"286.92,-182.39 293.91,-174.42 283.48,-176.29 286.92,-182.39\"/>\n",
       "</g>\n",
       "<!-- 20 &#45; município.21 &#45; o -->\n",
       "<g id=\"node8\" class=\"node\">\n",
       "<title>20 &#45; município.21 &#45; o</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"140.15\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"140.15\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">o</text>\n",
       "</g>\n",
       "<!-- 18 &#45; igual.20 &#45; município&#45;&gt;20 &#45; município.21 &#45; o -->\n",
       "<g id=\"edge7\" class=\"edge\">\n",
       "<title>18 &#45; igual.20 &#45; município&#45;&gt;20 &#45; município.21 &#45; o</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M140.15,-143.7C140.15,-135.98 140.15,-126.71 140.15,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"143.65,-118.1 140.15,-108.1 136.65,-118.1 143.65,-118.1\"/>\n",
       "</g>\n",
       "<!-- 23 &#45; São.24 &#45; a -->\n",
       "<g id=\"node11\" class=\"node\">\n",
       "<title>23 &#45; São.24 &#45; a</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"215.15\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"215.15\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">a</text>\n",
       "</g>\n",
       "<!-- 18 &#45; igual.23 &#45; São&#45;&gt;23 &#45; São.24 &#45; a -->\n",
       "<g id=\"edge10\" class=\"edge\">\n",
       "<title>18 &#45; igual.23 &#45; São&#45;&gt;23 &#45; São.24 &#45; a</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M295.99,-148.16C280.78,-137.41 258.86,-121.91 241.68,-109.76\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"243.38,-106.67 233.19,-103.76 239.33,-112.39 243.38,-106.67\"/>\n",
       "</g>\n",
       "<!-- 23 &#45; São.25 &#45; Bernardo -->\n",
       "<g id=\"node12\" class=\"node\">\n",
       "<title>23 &#45; São.25 &#45; Bernardo</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"314.15\" cy=\"-90\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"314.15\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Bernardo</text>\n",
       "</g>\n",
       "<!-- 18 &#45; igual.23 &#45; São&#45;&gt;23 &#45; São.25 &#45; Bernardo -->\n",
       "<g id=\"edge11\" class=\"edge\">\n",
       "<title>18 &#45; igual.23 &#45; São&#45;&gt;23 &#45; São.25 &#45; Bernardo</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M314.15,-143.7C314.15,-135.98 314.15,-126.71 314.15,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"317.65,-118.1 314.15,-108.1 310.65,-118.1 317.65,-118.1\"/>\n",
       "</g>\n",
       "<!-- 23 &#45; São.26 &#45; Campo -->\n",
       "<g id=\"node13\" class=\"node\">\n",
       "<title>23 &#45; São.26 &#45; Campo</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"429.15\" cy=\"-90\" rx=\"42.79\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"429.15\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">Campo</text>\n",
       "</g>\n",
       "<!-- 18 &#45; igual.23 &#45; São&#45;&gt;23 &#45; São.26 &#45; Campo -->\n",
       "<g id=\"edge12\" class=\"edge\">\n",
       "<title>18 &#45; igual.23 &#45; São&#45;&gt;23 &#45; São.26 &#45; Campo</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M333.92,-148.97C351.26,-138.41 376.8,-122.86 397.06,-110.53\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"398.95,-113.48 405.67,-105.29 395.31,-107.5 398.95,-113.48\"/>\n",
       "</g>\n",
       "<!-- 26 &#45; Campo.27 &#45; do -->\n",
       "<g id=\"node14\" class=\"node\">\n",
       "<title>26 &#45; Campo.27 &#45; do</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"429.15\" cy=\"-18\" rx=\"27\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"429.15\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">do</text>\n",
       "</g>\n",
       "<!-- 23 &#45; São.26 &#45; Campo&#45;&gt;26 &#45; Campo.27 &#45; do -->\n",
       "<g id=\"edge13\" class=\"edge\">\n",
       "<title>23 &#45; São.26 &#45; Campo&#45;&gt;26 &#45; Campo.27 &#45; do</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M429.15,-71.7C429.15,-63.98 429.15,-54.71 429.15,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"432.65,-46.1 429.15,-36.1 425.65,-46.1 432.65,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc6f9b39a10>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.parse_tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Node Mapper\n",
    "\n",
    "Como dito em [Arquitetura Geral](#arquitetura_geral), o módulo de **Query Tree Node Maper**, que no código é repesentado por `NodeMapper`, possui a função de mapear os nós da árvore de dependência para os elementos da estrutura SQL. Os tipos de nós, são: \n",
    "\n",
    "\n",
    "<a id=\"tipo_no\"></a>\n",
    "\n",
    "| Tipo de Nó |Componente SQL Correspondente |\n",
    "| :-- | :-- |\n",
    "| Select Node (SN) |palavra reservada SQL : SELECT |\n",
    "| Operator Node (ON) | operadores ( !=, >,<,=,  contains) |\n",
    "| Function Node (FN) | Funções de Agregação (AVG) |\n",
    "| Name Node (NN) | Nome de Relação ou de Atributo |\n",
    "| Value Node (VN) | Valor de um determinado atributo |\n",
    "| Quantifier Node (QN) | Palavras como ALL, ANY, EACH |\n",
    "| Logic Node (LN) | Operadores Booleanos (AND, OR, NOT) |\n",
    "\n",
    "Excluindo os Nós **Name** e **Value** nodes, todos os outros são definidos a partir de um arquivo xml. Esse arquivo se encontra dentro do diretório `zfiles`, como o nome de `tokens.xml` e possui o seguinte formato: \n",
    "``` xml\n",
    "<types>\n",
    "   <!-- Command Token, verb -->\n",
    "   <CMT_V>\n",
    "      <phrase>\n",
    "         tell\n",
    "         <example>Tell me all the books published in year 1993.</example>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         give\n",
    "         <example>Give me all the books published in year 1993.</example>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         return\n",
    "         <example>Return all the books published in year 1993.</example>\n",
    "      </phrase>\n",
    "   </CMT_V>\n",
    "   <!-- Function Token, adjective -->\n",
    "   <FT>\n",
    "      <phrase>\n",
    "         minimum\n",
    "         <function>min</function>\n",
    "         <example>Find the books with the minimum price.</example>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         most\n",
    "         <function>max</function>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         biggest\n",
    "         <function>max</function>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         least\n",
    "         <function>min</function>\n",
    "      </phrase>\n",
    "   </FT>\n",
    "   <!-- Operator Token, adj -->\n",
    "   <OT>\n",
    "      <phrase>\n",
    "         earlier\n",
    "         <operator>&lt;</operator>\n",
    "         <example>Find all the books of Ayn Rand, where the year of each book is earlier than the year of \"Fountain Head\".</example>\n",
    "      </phrase>\n",
    "      <phrase>\n",
    "         later\n",
    "         <operator>&gt;</operator>\n",
    "         <example>Find all the books of Ayn Rand, where the year of each book is later than the year of \"Fountain Head\".</example>\n",
    "      </phrase>\n",
    "   </OT>\n",
    "</types>\n",
    "```\n",
    "\n",
    "Assim, se quem estiver utilizando o Sistema quiser aumentar a granularidade e a interpretação do NaLIR, basta aumentar a lista de tokens deste arquivo. O código a seguir mostra as etapas de função do mapeamento.\n",
    "\n",
    "``` python \n",
    " \n",
    " def phrase_process(query, db, config):\n",
    "        # ...\n",
    "        \n",
    "        NodeMapper.tokenizer(query, tokens)\n",
    "        NodeMapper.delete_useless(query)\n",
    "        NodeMapper.map(query,db)\n",
    "        NodeMapper.individual_rank(query)\n",
    "        group_ranking = NodeMapper.group_ranking(query,db)\n",
    "        return NodeMapper.group_ranking_to_df(group_ranking)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "A primeira etapa `NodeMapper.tokenizer(query, tokens)` utiliza os tokens carregados do arquivo `tokens.xml` e mapeia corretamente os nós que exercem uma função diferente de Name Nodes e Value Nodes.  Nessa função a diferenciação acontece baseado na função sintática da palavra e na presença da palavra no arquivo de tokens. Por exemplo, se a palavra não estiver presente em tokens, e for um substantivo próprio ou comum, adjetivo ou um número cardinal, essa etapa assinala um tipo intermediario para o nó, `NTVT`. Isso indica para as fases seguintes que esse nós, apesar de não terem um tipo final, podem ser candidatos a algum mapeamento (Name Node ou Value Node).\n",
    "\n",
    "Em `delete_useless` todos os nós que não possuem tipo (`NA`) são deletados. Já em `map`, que será mostrado a seguir, busca todos os elementos de esquema e valores de banco de dados que podem fazer referencia aos nós \"candidatos\" a Name e Value Nodes dentro da árvore. \n",
    "\n",
    "\n",
    "``` python\n",
    "    def map(query, db):\n",
    "    parse_tree = query.parse_tree\n",
    "    all_nodes = parse_tree.all_nodes\n",
    "\n",
    "    for i in range(len(all_nodes)):\n",
    "        tree_node = all_nodes[i]\n",
    "        if tree_node.token_type == 'NTVT' or tree_node.token_type == 'JJ':\n",
    "            db.is_schema_exist(tree_node)\n",
    "            db.is_text_exist(tree_node)\n",
    "\n",
    "            if len(tree_node.mapped_elements) == 0:\n",
    "                tree_node.token_type = 'NA'\n",
    "\n",
    "        elif tree_node.token_type == 'VT':\n",
    "            OT = '='\n",
    "            if tree_node.parent.token_type == 'OT':\n",
    "                OT = tree_node.parent.function\n",
    "            elif len(tree_node.children) == 1 and tree_node.children[0].token_type == 'OT':\n",
    "                OT = tree_node.children[0].function\n",
    "            db.is_num_exist(OT, tree_node)\n",
    "            tree_node.token_type = 'VTNUM'\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Os candidatos para Name Nodes são recuperados em `db.is_schema_exist` e  para Value Nodes em `db.is_text_exist` e `db.is_num_exist`.  \n",
    "\n",
    "A função `individual_ranking` é responsável por calcular a similaridade entre um dado nó e os elementos de esquema mapeados para o mesmo, enquanto a função ``group_ranking`` é responsável por identificar a melhor configuração de mapeamento para todos nós. Essa escolha é feita baseada em:\n",
    "\n",
    " - Em como os nós estão dispostos na árvore\n",
    " - Na relação entre os elementos de esquema mapeados para os nós\n",
    " \n",
    " Essa relação é calculada no Grafo de Esquema, usando Djkistra para calcular a distãncia entre os elementos do esquema. Ao final desse processo, `group_ranking` classifica os nós candidatos `NTVT` em Name Nodes (`NT`) ou Value Nodes (`VT`).  \n",
    "\n",
    "Abaixo segue o exemplo da saida da função que executa o mapeamento dos nós."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:38.288137Z",
     "start_time": "2020-09-25T23:09:27.137697Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/someone/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package wordnet to /home/someone/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/someone/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TERMINOU NODE_MAPPER.TOKENIZER()\n",
      "group_ranking_to_df:  idade:casos.idade:NT;bernardo:casos.nome_munic:VT;\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Keyword</th>\n",
       "      <th>Table</th>\n",
       "      <th>Column</th>\n",
       "      <th>TAG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>idade</td>\n",
       "      <td>casos</td>\n",
       "      <td>idade</td>\n",
       "      <td>NT</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bernardo</td>\n",
       "      <td>casos</td>\n",
       "      <td>nome_munic</td>\n",
       "      <td>VT</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Keyword  Table      Column TAG\n",
       "0     idade  casos       idade  NT\n",
       "1  bernardo  casos  nome_munic  VT"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('punkt')\n",
    "NodeMapper.phrase_process(query,rdbms,config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:38.327908Z",
     "start_time": "2020-09-25T23:09:38.291260Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"116pt\" height=\"332pt\"\n",
       " viewBox=\"0.00 0.00 115.89 332.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 328)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-328 111.89,-328 111.89,4 -4,4\"/>\n",
       "<!-- 0.14 &#45; ROOT -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0.14 &#45; ROOT</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"53.95\" cy=\"-306\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"53.95\" y=\"-302.3\" font-family=\"Times,serif\" font-size=\"14.00\">ROOT</text>\n",
       "</g>\n",
       "<!-- 14 &#45; ROOT.15 &#45; retorne -->\n",
       "<g id=\"node2\" class=\"node\">\n",
       "<title>14 &#45; ROOT.15 &#45; retorne</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"53.95\" cy=\"-234\" rx=\"45.49\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"53.95\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\">retorne</text>\n",
       "</g>\n",
       "<!-- 0.14 &#45; ROOT&#45;&gt;14 &#45; ROOT.15 &#45; retorne -->\n",
       "<g id=\"edge1\" class=\"edge\">\n",
       "<title>0.14 &#45; ROOT&#45;&gt;14 &#45; ROOT.15 &#45; retorne</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.95,-287.7C53.95,-279.98 53.95,-270.71 53.95,-262.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.45,-262.1 53.95,-252.1 50.45,-262.1 57.45,-262.1\"/>\n",
       "</g>\n",
       "<!-- 15 &#45; retorne.16 &#45; idade -->\n",
       "<g id=\"node3\" class=\"node\">\n",
       "<title>15 &#45; retorne.16 &#45; idade</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"53.95\" cy=\"-162\" rx=\"36.29\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"53.95\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\">idade</text>\n",
       "</g>\n",
       "<!-- 14 &#45; ROOT.15 &#45; retorne&#45;&gt;15 &#45; retorne.16 &#45; idade -->\n",
       "<g id=\"edge2\" class=\"edge\">\n",
       "<title>14 &#45; ROOT.15 &#45; retorne&#45;&gt;15 &#45; retorne.16 &#45; idade</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.95,-215.7C53.95,-207.98 53.95,-198.71 53.95,-190.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.45,-190.1 53.95,-180.1 50.45,-190.1 57.45,-190.1\"/>\n",
       "</g>\n",
       "<!-- 16 &#45; idade.18 &#45; igual -->\n",
       "<g id=\"node4\" class=\"node\">\n",
       "<title>16 &#45; idade.18 &#45; igual</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"53.95\" cy=\"-90\" rx=\"33.6\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"53.95\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\">igual</text>\n",
       "</g>\n",
       "<!-- 15 &#45; retorne.16 &#45; idade&#45;&gt;16 &#45; idade.18 &#45; igual -->\n",
       "<g id=\"edge3\" class=\"edge\">\n",
       "<title>15 &#45; retorne.16 &#45; idade&#45;&gt;16 &#45; idade.18 &#45; igual</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.95,-143.7C53.95,-135.98 53.95,-126.71 53.95,-118.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.45,-118.1 53.95,-108.1 50.45,-118.1 57.45,-118.1\"/>\n",
       "</g>\n",
       "<!-- 18 &#45; igual.25 &#45; Bernardo -->\n",
       "<g id=\"node5\" class=\"node\">\n",
       "<title>18 &#45; igual.25 &#45; Bernardo</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"53.95\" cy=\"-18\" rx=\"53.89\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"53.95\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">Bernardo</text>\n",
       "</g>\n",
       "<!-- 16 &#45; idade.18 &#45; igual&#45;&gt;18 &#45; igual.25 &#45; Bernardo -->\n",
       "<g id=\"edge4\" class=\"edge\">\n",
       "<title>16 &#45; idade.18 &#45; igual&#45;&gt;18 &#45; igual.25 &#45; Bernardo</title>\n",
       "<path fill=\"none\" stroke=\"black\" d=\"M53.95,-71.7C53.95,-63.98 53.95,-54.71 53.95,-46.11\"/>\n",
       "<polygon fill=\"black\" stroke=\"black\" points=\"57.45,-46.1 53.95,-36.1 50.45,-46.1 57.45,-46.1\"/>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc6f9aca390>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query.parse_tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Entity Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse módulo é a primeira fase do **Tree Strucutre Adjustor**. Antes de gerar as árvores seguindo a gramática, **Entity Resolution** verifica quais nós referenciam o mesmo atributo na árvore. Essa relação é utilizada tanto na geração de árvores derivadas, quanto na pontuação das árvores. Segue abaixo o código da função ``entity_resolute``, seguido da saída da mesma: \n",
    "\n",
    "\n",
    "``` python \n",
    "\n",
    "def entity_resolute(query):\n",
    "    query.entities = []\n",
    "    nodes = query.parse_tree.all_nodes\n",
    "    for i in range(len(nodes)):\n",
    "        left = nodes[i]\n",
    "        if left.get_choice_map() == None:\n",
    "            continue\n",
    "        left_map = left.get_choice_map().schema_element\n",
    "        for j in range(i+1, len(nodes)):\n",
    "            right = nodes[j]\n",
    "            if right.get_choice_map() == None:\n",
    "                continue\n",
    "            right_map = right.get_choice_map().schema_element\n",
    "            if left_map == right_map:\n",
    "                if left.token_type == \"VTTEXT\" and left.token_type == \"VTTEXT\":\n",
    "                    if left.label == right.label:\n",
    "                        entity_pair = EntityPair(left, right)\n",
    "                        query.entities.append(entity_pair)\n",
    "                    else:\n",
    "                        continue\n",
    "                if left.token_type == \"VTTEXT\" and right.token_type == \"NT\" or\\\n",
    "                 left.token_type == \"NT\" and right.token_type == \"VTTEXT\" or\\\n",
    "                 left.token_type == \"NT\" and right.token_type == \"NT\":\n",
    "                    if abs(left.word_order - right.word_order) > 2:\n",
    "                        continue\n",
    "                    else:\n",
    "                        entity_pair = EntityPair(left, right)\n",
    "                        query.entities.append(entity_pair)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:38.419847Z",
     "start_time": "2020-09-25T23:09:38.329289Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_resolute(query)\n",
    "query.entities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tree Structure Adjustor\n",
    "\n",
    "Este módulo é responsável por:\n",
    " * Verificar se a árvore gerada condiz com a gramática especificada\n",
    " * Gerar Árvores variantes da Árvore de Parser original que seguem a gramática\n",
    " * Ranquear todas as Árvores, e escolher a com maior pontuação para a etapa de tradução.\n",
    " \n",
    "A gramática que deve ser seguida para as árvores é a seguinte:\n",
    "```\n",
    "\n",
    "Q -> (SClause)(ComplexCondition)*\n",
    "SClause -> SELECT + GNT\n",
    "ComplexCondition -> ON + (leftSubtree*rightSubtree)\n",
    "leftSubtree -> GNP\n",
    "rightSubtree -> GNP |VN | MIN | MAX\n",
    "GNP -> (FN + GNP) | NP\n",
    "NP -> NN + (NN)*(Condition)*\n",
    "Condition-> VN | (ON + VN)\n",
    "```\n",
    "\n",
    "Em que: \n",
    "* VN, NN, FN, ON são tipos de nós referenciados na [tabela de tipos de nós](#tipo_no)\n",
    "* `+` representa relações de pai-filho entre os nós\n",
    "* `*` representa relações de irmão entre os nós\n",
    "\n",
    "\n",
    "A função `tree_structure_adjust`, listada a seguir, é a responsável por executar o processo de geração das árvores.\n",
    "\n",
    "``` python\n",
    "    \tdef tree_structure_adjust(query,  db):\n",
    "\t\tquery.adjusting_trees = []\n",
    "\t\tquery.invalid = []\n",
    "\t\tpre_trees = {}\n",
    "   \n",
    "\t\tTreeStructureAdjustor.adjust(query, db,False, pre_trees)\n",
    "\t\tif len(query.adjusting_trees) == 0 or (len(query.adjusting_trees) > 0 and query.adjusting_trees[0].cost > 3):\n",
    "\t\t\tmax_min = False\n",
    "\t\t\tfor node in query.parse_tree.all_nodes:\n",
    "\t\t\t\tif node.function == 'max' or node.function == 'min':\n",
    "\t\t\t\t\tmax_min = True\n",
    "\t\t\t\t\tbreak\n",
    "\n",
    "\t\t\tif max_min:\n",
    "\t\t\t\tTreeStructureAdjustor.adjust(query, db, True, pre_trees)\n",
    "\n",
    "\t\tadjusted_trees = query.adjusting_trees\n",
    "\t\tadjusted_trees.sort(key=lambda elem : ((elem.weight * 100) - elem.cost) * -1 )\n",
    "\t\tfor i  in range(len(adjusted_trees)):\n",
    "\t\t\tadjusted_tree = adjusted_trees[i]\n",
    "\n",
    "\t\t\tfor j in range(len(adjusted_tree.all_nodes)):\n",
    "\t\t\t\tnode = adjusted_trees[i].all_nodes[j]\n",
    "\t\t\t\tnode.children.sort(key=lambda elem: elem.node_id)\n",
    "\t\t\thash(adjusted_tree)\n",
    "\n",
    "\n",
    "\t\tlinked_list = []\n",
    "\t\ti = 0\n",
    "\t\twhile i  < len(adjusted_trees):\n",
    "\t\t\tif adjusted_trees[i].hash_num in linked_list:\n",
    "\t\t\t\tadjusted_trees.pop(i)\n",
    "\t\t\t\ti-=1\n",
    "\t\t\telse:\n",
    "\t\t\t\tlinked_list += [adjusted_trees[i].hash_num]\n",
    "\t\t\ti+=1\n",
    "\n",
    "\t\tTreeStructureAdjustor.build_adjusted_trees(query)\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "Como podemos observar, primeiramente é gerado uma série de árvores, chamadas `adjusting_trees`. Depois de ordenarmos estas árvores intermediárias, ordenamos todos os filhos de todos os nós, e retiramos as árvores repetidas da lista. A partir dai, geramos a lista final de árvores, no método `build_adjusted_trees`. A seguir, verificamos a saída final do método."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:39.566174Z",
     "start_time": "2020-09-25T23:09:38.422232Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"85pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 84.69 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 80.69,-40 80.69,4 -4,4\"/>\n",
       "<!-- 0.13 &#45; ROOT -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0.13 &#45; ROOT</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"38.35\" cy=\"-18\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"38.35\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">ROOT</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc6f9acc050>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TreeStructureAdjustor.tree_structure_adjust(query,rdbms)\n",
    "query.query_tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explainer\n",
    "\n",
    "Este módulo, é a última etapa de **Tree Strucuture Adjustor**. Após selecionar a árvore com maior pontuação, este módulo insere nós com o intuito de facilitar a tradução da consulta para linguagem natural para a SQL. Outro objetivo desta etapa é retirar elipses da consulta.  O código asseguir, mostra que esta função apenas itera sobre os nós da árvore e verifica se pode inserir outros nós que já estão na árvore, em um dos seus nós filhos.\n",
    "\n",
    "\n",
    "\n",
    "```python \n",
    "  def explain(query):\n",
    "    for i in query.adjusted_trees:\n",
    "        nl = explain_tree(i)\n",
    "        query.nl_sentence.append(nl)\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"UTF-8\" standalone=\"no\"?>\n",
       "<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\n",
       " \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\n",
       "<!-- Generated by graphviz version 2.43.0 (0)\n",
       " -->\n",
       "<!-- Title: %3 Pages: 1 -->\n",
       "<svg width=\"85pt\" height=\"44pt\"\n",
       " viewBox=\"0.00 0.00 84.69 44.00\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\n",
       "<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 40)\">\n",
       "<title>%3</title>\n",
       "<polygon fill=\"white\" stroke=\"transparent\" points=\"-4,4 -4,-40 80.69,-40 80.69,4 -4,4\"/>\n",
       "<!-- 0.13 &#45; ROOT -->\n",
       "<g id=\"node1\" class=\"node\">\n",
       "<title>0.13 &#45; ROOT</title>\n",
       "<ellipse fill=\"none\" stroke=\"black\" cx=\"38.35\" cy=\"-18\" rx=\"38.19\" ry=\"18\"/>\n",
       "<text text-anchor=\"middle\" x=\"38.35\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\">ROOT</text>\n",
       "</g>\n",
       "</g>\n",
       "</svg>\n"
      ],
      "text/plain": [
       "<graphviz.dot.Digraph at 0x7fc6f9ac1490>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "explain(query)\n",
    "query.query_tree.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SQL Translator\n",
    "\n",
    "O último módulo da arquitetura do NaLIR, é responsável por receber a Árvore Consulta (`query_tree`), gerada pelo **Query Tree Strucutre Adjustor** e retornar a SQL correspondente.  A função `translate`, listada a seguir, é a responsável por executar esse processo dentro do módulo. \n",
    "\n",
    "Como vemos no código a estrutura utilizada para converter a árvore em uma string SQL é uma estrutura chamada `block`. Cada `block` identifica um nivel de consulta. Assim, consultas que não possuem subconsultas, possuem apenas um bloco. Consultas que possuem agregação, ou consultas aninhadas, possuem dois ou mais blocos.\n",
    "\n",
    "```python\n",
    "def translate(query, db):\n",
    "    pre_structure_adjustor(query)\n",
    "    if len(query.query_tree.all_nodes) < 2:\n",
    "        return\n",
    "    query.blocks = []\n",
    "    block_split(query)\n",
    "    query.blocks[0].node_edge_gen(query.main_block, query.query_tree, query.graph)\n",
    "    query.blocks[0].translate(query.main_block, query.query_tree)\n",
    "    query.translated_sql = query.blocks[0].sql\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-25T23:09:39.725094Z",
     "start_time": "2020-09-25T23:09:39.638591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SELECT casos.idade\n",
      "FROM casos\n",
      "WHERE casos.nome_munic LIKE \"%Bernardo%\"\n"
     ]
    }
   ],
   "source": [
    "translate(query, rdbms)\n",
    "print(query.translated_sql)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Outras consultas que também podem ser executadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "'return me the homepage of PVLDB.',\n",
    "'return me the homepage of \"H. V. Jagadish\".',\n",
    "'return me the abstract of \"Making database systems usable\".',\n",
    "'return me the year of \"Making database systems usable\"',\n",
    "'return me the papers after 2000.',\n",
    "'return me the homepage of the VLDB conference.',\n",
    "'return me all the keywords.',\n",
    "'return me all the organizations.',\n",
    "'return me all the organizations in \"North America\".',\n",
    "'return me the homepage of \"University of Michigan\".',\n",
    "'return me the number of references of \"Making database systems usable\".',\n",
    "'return me the number of citations of \"Making database systems usable\".',\n",
    "'return me the year of \"Making database systems usable\".',\n",
    "'return me the paper with more than 200 citations.',\n",
    "'return me the authors who have papers in PVLDB 2010.',\n",
    "'return me the authors who have papers in PVLDB after 2010.',\n",
    "'return me the authors who have papers in VLDB conference in 2002.',\n",
    "'return me the authors who have papers in VLDB conference before 2002.',\n",
    "'return me the authors who have papers in VLDB conference before 2002 after 1995.',\n",
    "'return me the authors who have papers in VLDB conference before 1995 or after 2002.',\n",
    "'return me the area of PVLDB.',\n",
    "'return me the authors who have papers in PVLDB.',\n",
    "'return me the organization \"H. V. Jagadish\" is in.',\n",
    "'return me the conferences, which have papers by \"H. V. Jagadish\".',\n",
    "'return me the journals, which have papers by \"H. V. Jagadish\".',\n",
    "'return me the domain where \"H. V. Jagadish\" is focused.',\n",
    "'return me the authors of \"Making database systems usable\".',\n",
    "'return me the conference, which published \"Making database systems usable\".',\n",
    "'return me the references of \"Making database systems usable\".',\n",
    "'return me the citations of \"Making database systems usable\".',\n",
    "'return me the papers by \"H. V. Jagadish\".',\n",
    "'return me the papers on VLDB conference.',\n",
    "'return me the papers on PVLDB.',\n",
    "'return me the papers on PVLDB after 2000.',\n",
    "'return me the papers on VLDB conference after 2000.',\n",
    "'return me the papers by \"H. V. Jagadish\" on PVLDB.',\n",
    "'return me the papers by \"H. V. Jagadish\" on VLDB conference.',\n",
    "'return me the papers by \"H. V. Jagadish\" after 2000.',\n",
    "'return me the papers by \"H. V. Jagadish\" on PVLDB after 2000.',\n",
    "'return me the papers by \"H. V. Jagadish\" on VLDB conference after 2000.',\n",
    "'return me the area of the VLDB conference.',\n",
    "'return me the authors who have papers in the VLDB conference.',\n",
    "'return me all the keywords in Databases area.',\n",
    "'return me all the papers, which contain the keyword \"Natural Language\".',\n",
    "'return me the keywords of \"Making database systems usable\".',\n",
    "'return me the keywords related to \"H. V. Jagadish\".',\n",
    "'return me the keywords in VLDB conference.',\n",
    "'return me the keywords in PVLDB.',\n",
    "'return me the keywords in the papers of \"University of Michigan\".',\n",
    "'return me the papers of \"H. V. Jagadish\" containing keyword \"User Study\".',\n",
    "'return me the papers in PVLDB containing keyword \"Keyword search\".',\n",
    "'return me the papers in VLDB conference containing keyword \"Information Retrieval\".',\n",
    "'return me the authors who have papers containing keyword \"Relational Database\".',\n",
    "'return me all the organizations in Databases area.',\n",
    "'return me all the organizations in Databases area located in \"North America\".',\n",
    "'return me all the researchers in \"University of Michigan\".',\n",
    "'return me all the researchers in Databases area in \"University of Michigan\".',\n",
    "'return me all the papers in \"University of Michigan\".',\n",
    "'return me all the papers after 2000 in \"University of Michigan\".',\n",
    "'return me all the papers in VLDB conference in \"University of Michigan\".',\n",
    "'return me all the papers in PVLDB in \"University of Michigan\".',\n",
    "'return me all the papers in VLDB after 2000 in \"University of Michigan\".',\n",
    "'return me all the papers in PVLDB after 2000 in \"University of Michigan\".',\n",
    "'return me the paper in Databases area with more than 200 citations.',\n",
    "'return me the paper in PVLDB with more than 200 citations.',\n",
    "'return me the paper in VLDB conference with more than 200 citations.',\n",
    "'return me the paper by \"H. V. Jagadish\" with more than 200 citations.',\n",
    "'return me the papers by \"H. V. Jagadish\" on PVLDB with more than 200 citations.',\n",
    "'return me the papers by \"H. V. Jagadish\" on VLDB conference with more than 200 citations.',\n",
    "'return me the paper after 2000 with more than 200 citations.',\n",
    "'return me the paper after 2000 in Databases area with more than 200 citations.',\n",
    "'return me the paper after 2000 in PVLDB with more than 200 citations.',\n",
    "'return me the paper after 2000 in VLDB conference with more than 200 citations.',\n",
    "'return me the number of conferences which have papers by \"H. V. Jagadish\".',\n",
    "'return me the number of journals which have papers by \"H. V. Jagadish\".',\n",
    "'return me the number of papers written by \"H. V. Jagadish\" in each year.',\n",
    "'return me the number of authors of \"Making database systems usable\".',\n",
    "'return me the number of citations of \"Making database systems usable\" in each year.',\n",
    "'return me the number of papers by \"H. V. Jagadish\".',\n",
    "'return me the number of papers on VLDB conference.',\n",
    "'return me the number of papers on PVLDB.',\n",
    "'return me the number of papers after 2000.',\n",
    "'return me the number of papers on PVLDB after 2000.',\n",
    "'return me the number of papers on VLDB conference after 2000.',\n",
    "'return me the number of papers by \"H. V. Jagadish\" on PVLDB.',\n",
    "'return me the number of papers by \"H. V. Jagadish\" on VLDB conference.',\n",
    "'return me the number of papers by \"H. V. Jagadish\" after 2000.',\n",
    "'return me the number of papers by \"H. V. Jagadish\" on PVLDB after 2000.',\n",
    "'return me the number of papers by \"H. V. Jagadish\" on VLDB conference after 2000.',\n",
    "'return me the number of keywords.',\n",
    "'return me the number of keywords in Databases area.',\n",
    "'return me the number of papers which contain the keyword \"Natural Language\".',\n",
    "'return me the number of the keywords of \"Making database systems usable\".',\n",
    "'return me the number of the keywords related to \"H. V. Jagadish\".',\n",
    "'return me the number of keywords in VLDB conference.',\n",
    "'return me the number of keywords in PVLDB.',\n",
    "'return me the number of keywords in the papers of \"University of Michigan\".',\n",
    "'return me the number of the papers of \"H. V. Jagadish\" containing keyword \"User Study\".',\n",
    "'return me the number of papers in PVLDB containing keyword \"Keyword search\".',\n",
    "'return me the number of papers in VLDB conference containing keyword \"Information Retrieval\".',\n",
    "'return me the number of authors who have papers containing keyword \"Relational Database\".',\n",
    "'return me the total citations of the papers containing keyword \"Natural Language\"',\n",
    "'return me the number of the organizations.',\n",
    "'return me the number of the organizations in \"North America\".',\n",
    "'return me the number of organizations in Databases area.',\n",
    "'return me the number of organizations in Databases area located in \"North America\".',\n",
    "'return me the number of papers in \"University of Michigan\".',\n",
    "'return me the number of papers in \"University of Michigan\" in Databases area.',\n",
    "'return me the number of papers after 2000 in \"University of Michigan\".',\n",
    "'return me the number of papers in VLDB conference in \"University of Michigan\".',\n",
    "'return me the number of papers in PVLDB in \"University of Michigan\".',\n",
    "'return me the number of papers in VLDB after 2000 in \"University of Michigan\".',\n",
    "'return me the number of papers in PVLDB after 2000 in \"University of Michigan\".',\n",
    "'return me the total citations of the papers in \"University of Michigan\".',\n",
    "'return me the number of researchers in \"University of Michigan\".',\n",
    "'return me the number of researchers in Databases area in \"University of Michigan\".',\n",
    "'return me the number of authors who have papers in PVLDB.',\n",
    "'return me the number of authors who have papers in the VLDB conference.',\n",
    "'return me the number of papers published on PVLDB before 2000.',\n",
    "'return me the number of papers published in the VLDB conference before 2000.',\n",
    "'return me the total citations of all the papers in PVLDB.',\n",
    "'return me the citations of each paper in PVLDB.',\n",
    "'return me the total citations of papers in PVLDB in 2005.',\n",
    "'return me the total citations of papers in PVLDB before 2005.',\n",
    "'return me the total citations of papers in PVLDB in each year.',\n",
    "'return me the number of papers published in PVLDB in each year.',\n",
    "'return me the total citations of all the papers in the VLDB conference.',\n",
    "'return me the citations of each paper in the VLDB conference.',\n",
    "'return me the total citations of papers in the VLDB conference in 2005.',\n",
    "'return me the total citations of papers in the VLDB conference before 2005.',\n",
    "'return me the total citations of papers in the VLDB conference in each year.',\n",
    "'return me the number of papers published in the VLDB conference in each year.',\n",
    "'return me the authors who have cooperated both with \"H. V. Jagadish\" and \"Divesh Srivastava\".',\n",
    "'return me the authors who have cooperated with \"H. V. Jagadish\" or \"Divesh Srivastava\".',\n",
    "'return me the authors who have cooperated with \"H. V. Jagadish\" after 2000.',\n",
    "'return me the papers written by \"H. V. Jagadish\" and \"Divesh Srivastava\".',\n",
    "'return me the papers written by \"H. V. Jagadish\" and \"Yunyao Li\" after 2005.',\n",
    "'return me the papers written by \"H. V. Jagadish\" and \"Yunyao Li\" on PVLDB.',\n",
    "'return me the papers written by \"H. V. Jagadish\" and \"Yunyao Li\" on PVLDB after 2005.',\n",
    "'return me the authors who have cooperated with \"H. V. Jagadish\".',\n",
    "'return me the papers written by \"H. V. Jagadish\" and \"Divesh Srivastava\" before 2000.',\n",
    "'return me the authors who have cited the papers by \"H. V. Jagadish\".',\n",
    "'return me the number of papers written by \"H. V. Jagadish\" and \"Divesh Srivastava\".',\n",
    "'return me the number of papers written by \"H. V. Jagadish\" and \"Divesh Srivastava\" before 2000.',\n",
    "'return me the number of papers written by \"H. V. Jagadish\", \"Yunyao Li\", and \"Cong Yu\".',\n",
    "'return me the number of authors who have cooperated with \"H. V. Jagadish\".',\n",
    "'return me the number of authors who have cited the papers by \"H. V. Jagadish\".',\n",
    "'return me the papers written by \"H. V. Jagadish\" and \"Divesh Srivastava\" with more than 200 citations.',\n",
    "'return me the author who has the most number of papers containing keyword \"Relational Database\".',\n",
    "'return me the conference that has the most number of papers containing keyword \"Relational Database\".',\n",
    "'return me the journal that has the most number of papers containing keyword \"Relational Database\".',\n",
    "'return me the number of authors who have more than 10 papers containing keyword \"Relational Database\".',\n",
    "'return me the number of the conferences, which have more than 60 papers containing keyword \"Relational Database\".',\n",
    "'return me the number of the journals, which have more than 60 papers containing keyword \"Relational Database\".',\n",
    "'return me the number of the authors who have more than 10 papers containing keyword \"Relational Database\".',\n",
    "'return me the number of conferences, which have more than 60 papers containing keyword \"Relational Database\".',\n",
    "'return me the number of journals, which have more than 60 papers containing keyword \"Relational Database\".',\n",
    "'return me the number of keywords, which have been contained by more than 100 papers in VLDB conference.',\n",
    "'return me the number of keywords, which have been contained by more than 100 papers in PVLDB.',\n",
    "'return me the number of keywords, which have been contained by more than 10 papers of \"H. V. Jagadish\".',\n",
    "'return me the keyword, which have been contained by the most number of papers in VLDB conference.',\n",
    "'return me the keyword, which have been contained by the most number of papers in PVLDB.',\n",
    "'return me the keyword, which have been contained by the most number of papers by \"H. V. Jagadish\".',\n",
    "'return me the journal, which has the most number of papers containing keyword \"Relational Database\".',\n",
    "'return me the conference, which has the most number of papers containing keyword \"Relational Database\".',\n",
    "'return me the author who has the most number of papers containing keyword \"Relational Database\".',\n",
    "'return me the author in the \"University of Michigan\" whose papers have the most total citations.',\n",
    "'return me the author in the \"University of Michigan\" whose papers in Databases area have the most total citations.',\n",
    "'return me the papers written by \"H. V. Jagadish\" and \"Divesh Srivastava\" with the most number of citations.',\n",
    "'return me the conferences, which have more than 10 papers by \"H. V. Jagadish\".',\n",
    "'return me the conference, which have the most number of papers by \"H. V. Jagadish\".',\n",
    "'return me the journals, which have more than 10 papers by \"H. V. Jagadish\".',\n",
    "'return me the journal, which have the most number of papers by \"H. V. Jagadish\".',\n",
    "'return me the paper with the most citations.',\n",
    "'return me the paper in Databases area with the most citations.',\n",
    "'return me the paper in PVLDB with the most citations.',\n",
    "'return me the paper in VLDB conference with the most citations.',\n",
    "'return me the paper by \"H. V. Jagadish\" with the most citations.',\n",
    "'return me the paper after 2000 with the most citations.',\n",
    "'return me the paper after 2000 in Databases area with the most citations.',\n",
    "'return me the paper after 2000 in PVLDB with the most citations.',\n",
    "'return me the paper after 2000 in VLDB conference with the most citations.',\n",
    "'return me the authors who have more than 10 papers in PVLDB.',\n",
    "'return me the authors who have the most number of papers in PVLDB.',\n",
    "'return me the authors who have more than 10 papers containing keyword \"Relational Database\".',\n",
    "'return me the conferences, which have more than 60 papers containing keyword \"Relational Database\".',\n",
    "'return me the journals, which have more than 60 papers containing keyword \"Relational Database\".',\n",
    "'return me the keywords, which have been contained by more than 100 papers in VLDB conference.',\n",
    "'return me the keywords, which have been contained by more than 100 papers in PVLDB.',\n",
    "'return me the keywords, which have been contained by more than 10 papers of \"H. V. Jagadish\".',\n",
    "'return me the authors who have more than 10 papers in the VLDB conference.',\n",
    "'return me the author who has the most number of papers in the VLDB conference.',\n",
    "'return me the author in the \"University of Michigan\" whose papers have more than 5000 total citations.',\n",
    "'return me the author in the \"University of Michigan\" in Databases area whose papers have more than 5000 total citations.']\n",
    "# just to iggnore this cell\n",
    "queries = []\n",
    "\n",
    "sql_queries = []\n",
    "for query in queries:\n",
    "    sql_query = run_query(query, rdbms, config)\n",
    "    sql_queries += [sql_query]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_queries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Teste você mesmo !"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = 'return me all the publications in VLDB conference in \"University of Michigan\".' # ponha sua consulta aqui\n",
    "query = 'devolva tudo onde o município é \"Sao Bernardo do Campo\"'\n",
    "run_query(query, rdbms, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.2",
    "jupytext_version": "1.4.2"
   }
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
